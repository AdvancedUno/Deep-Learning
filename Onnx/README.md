ONNX stands for Open Neural Network Exchange.




https://artwork.lfaidata.foundation/projects/onnx/
When people build models using different libraries or platforms, they often face limitations with deploying models to different devices, languagues, or even to different platforms.

The key to solving this problem is using ONNX.

ONNX is an open standard for machine learning model interoperability developed as an open source library, mainly led by Microsoft and Facebook.



What ONNX does is establish a standard building block of deep learning or neural network models.

This enables AI researchers and developers to use models in different compilers, frameworks, and devices.


https://medium.com/codait/contribute-to-the-open-neural-network-exchange-onnx-5cfff6889761

ONNX makes AI developers' lives easier. It helps to resolve the challenge of software and hardware dependency with AI models.

Thanks to ONNX, people can now easily deploy the same models to various devices, such as Hardware or even Edge devices.



ONNX is widely supported, such as Pytorch, TensorFlow, and Caffe.

With ONNX people can develop models in the framework they want and later, they can just simply convert their models to ONNX format to deploy them to different tools and devices.



If you have an interest in ONNX, you can go to the ONNX Github (https://github.com/onnx).



Next time, I will talk about how to use ONNX by converting a PyTorch model to an ONNX model to inference the model in C++.





References:

https://medium.com/codait/contribute-to-the-open-neural-network-exchange-onnx-5cfff6889761

https://microsoft.github.io/ai-at-edge/docs/onnx/

https://blog.roboflow.com/what-is-onnx/